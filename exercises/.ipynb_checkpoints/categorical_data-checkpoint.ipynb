{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Categorical Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adult Census Income Data Set: `datasets/adult.csv`\n",
    "\n",
    "Prediction task is to determine whether a person makes over 50K a year. \n",
    "See for more information: https://www.kaggle.com/uciml/adult-census-income\n",
    "\n",
    "(<b>Note</b>: the attribute `fnlwgt` pertains to  a weight attribute which is a demographic score assigned to an individual based on information such as state of residence and type of employment. People with similar demographic characteristics\n",
    "should have similar weights.)\n",
    "\n",
    "Source: https://cseweb.ucsd.edu/classes/wi17/cse258-a/reports/a120.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.) Import relevant libraries (don't forget the scikit preprocessing library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.) Load `adult.csv` dataset located in the folder `datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = '../datasets/adult.csv'\n",
    "df = pd.read_csv(filename, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.) Inspect your data. Use, head(), shapeNotice that some values are `?`. These indicate missing values. \n",
    "\n",
    "Tip: You can use \n",
    "```python\n",
    "df.describe(include = 'all')\n",
    "```\n",
    "to describe your data. \n",
    "The `include = \"all\"` arguments allows you to see the summary of both numerical and object (string) features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.) Extract features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = None\n",
    "y = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.) Using the tutorial and other additional resources, find ways to appropriately handle the categorical data in the data set. Also, take note of redundant features and missing values, and make sure you take care of those too. \n",
    "\n",
    "Tip: Some models perform worse with a large number of features. Observe the data and decide how to encode certain features without the feature space blowing up. \n",
    "\n",
    "Good luck! (ง •̀ω•́)ง✧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.) Once you're done pre-processing the data, it's time to apply our machine learning algorithms!\n",
    "- As usual, split the dataset. For uniformity, use an 80/20 split and set the random state (seed) to 7.\n",
    "- Apply your favorite machine learning algorithms and evaluate the accuracy. Which algorithm gives you the highest accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.) Does scaling the data improve or worsen the performance ofthe models? Try it to find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Share your work! :D \n",
    "Upload this to our github repo and share your knowledge :,D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
